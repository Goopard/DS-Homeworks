{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.4,\n",
    "        zoom_range=0.4,\n",
    "        horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train', target_size=(150, 150), batch_size=batch_size, class_mode='binary', shuffle=False)\n",
    "test_generator = test_datagen.flow_from_directory('test', target_size=(150, 150), batch_size=batch_size, class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for image, label in train_generator:\n",
    "    if len(train_labels) == 498:\n",
    "        break\n",
    "    train_labels += list(label)\n",
    "    \n",
    "test_labels = []\n",
    "\n",
    "for image, label in test_generator:\n",
    "    if len(test_labels) == 500:\n",
    "        break\n",
    "    test_labels += list(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "100/100 [==============================] - 66s 661ms/step - loss: 0.7902 - accuracy: 0.5558\n",
      "Epoch 2/8\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 0.6924 - accuracy: 0.5873\n",
      "Epoch 3/8\n",
      "100/100 [==============================] - 65s 651ms/step - loss: 0.7035 - accuracy: 0.5834\n",
      "Epoch 4/8\n",
      "100/100 [==============================] - 64s 637ms/step - loss: 0.6438 - accuracy: 0.6463\n",
      "Epoch 5/8\n",
      "100/100 [==============================] - 64s 639ms/step - loss: 0.6273 - accuracy: 0.6697\n",
      "Epoch 6/8\n",
      "100/100 [==============================] - 64s 636ms/step - loss: 0.6121 - accuracy: 0.6900\n",
      "Epoch 7/8\n",
      "100/100 [==============================] - 64s 635ms/step - loss: 0.5868 - accuracy: 0.7022\n",
      "Epoch 8/8\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.5495 - accuracy: 0.7317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9525f098d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model.predict_generator(test_generator)\n",
    "accuracy_score(labels, predicts.reshape(-1) >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train = list(vgg_model.predict(train_generator))\n",
    "vgg_test = list(vgg_model.predict(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train_other = np.array([array.reshape(-1) for array in vgg_train])\n",
    "vgg_test_other = np.array([array.reshape(-1) for array in vgg_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "498/498 [==============================] - 2s 3ms/sample - loss: 1.3946 - accuracy: 0.5663\n",
      "Epoch 2/25\n",
      "498/498 [==============================] - 0s 964us/sample - loss: 0.6680 - accuracy: 0.6888\n",
      "Epoch 3/25\n",
      "498/498 [==============================] - 0s 934us/sample - loss: 0.5461 - accuracy: 0.7510\n",
      "Epoch 4/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.5030 - accuracy: 0.7791\n",
      "Epoch 5/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.4270 - accuracy: 0.8293\n",
      "Epoch 6/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.4616 - accuracy: 0.8153\n",
      "Epoch 7/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.2950 - accuracy: 0.8775\n",
      "Epoch 8/25\n",
      "498/498 [==============================] - 0s 948us/sample - loss: 0.2818 - accuracy: 0.8735\n",
      "Epoch 9/25\n",
      "498/498 [==============================] - 0s 967us/sample - loss: 0.2763 - accuracy: 0.8976\n",
      "Epoch 10/25\n",
      "498/498 [==============================] - 0s 952us/sample - loss: 0.1332 - accuracy: 0.9438\n",
      "Epoch 11/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.1975 - accuracy: 0.9237\n",
      "Epoch 12/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.1525 - accuracy: 0.9378\n",
      "Epoch 13/25\n",
      "498/498 [==============================] - 0s 953us/sample - loss: 0.2242 - accuracy: 0.9177\n",
      "Epoch 14/25\n",
      "498/498 [==============================] - 0s 979us/sample - loss: 0.0675 - accuracy: 0.9779\n",
      "Epoch 15/25\n",
      "498/498 [==============================] - 0s 961us/sample - loss: 0.0740 - accuracy: 0.9699\n",
      "Epoch 16/25\n",
      "498/498 [==============================] - 0s 946us/sample - loss: 0.0893 - accuracy: 0.9639\n",
      "Epoch 17/25\n",
      "498/498 [==============================] - 0s 959us/sample - loss: 0.0992 - accuracy: 0.9618\n",
      "Epoch 18/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.0750 - accuracy: 0.9739\n",
      "Epoch 19/25\n",
      "498/498 [==============================] - 0s 997us/sample - loss: 0.0950 - accuracy: 0.9598\n",
      "Epoch 20/25\n",
      "498/498 [==============================] - 0s 947us/sample - loss: 0.0403 - accuracy: 0.9859\n",
      "Epoch 21/25\n",
      "498/498 [==============================] - 0s 954us/sample - loss: 0.0446 - accuracy: 0.9859\n",
      "Epoch 22/25\n",
      "498/498 [==============================] - 0s 978us/sample - loss: 0.0428 - accuracy: 0.9880\n",
      "Epoch 23/25\n",
      "498/498 [==============================] - 0s 989us/sample - loss: 0.0650 - accuracy: 0.9779\n",
      "Epoch 24/25\n",
      "498/498 [==============================] - 0s 999us/sample - loss: 0.0486 - accuracy: 0.9799\n",
      "Epoch 25/25\n",
      "498/498 [==============================] - 1s 1ms/sample - loss: 0.0213 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f937d55ccf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(vgg_train_other, np.array(train_labels), epochs=25, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(vgg_test_other).reshape(-1)\n",
    "accuracy_score([0] * 250 + [1] * 250, predictions >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('top_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning of the top CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.load_weights('top_weights.h5')\n",
    "\n",
    "all_layers = model.layers + top_model.layers\n",
    "model = Sequential(all_layers)\n",
    "\n",
    "for layer in model.layers[:14]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 208s 2s/step - loss: 0.7177 - accuracy: 0.7381\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 207s 2s/step - loss: 0.3497 - accuracy: 0.8447\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 206s 2s/step - loss: 0.2611 - accuracy: 0.8787\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 210s 2s/step - loss: 0.1839 - accuracy: 0.9236\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 206s 2s/step - loss: 0.1495 - accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 207s 2s/step - loss: 0.1236 - accuracy: 0.9461\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 211s 2s/step - loss: 0.0984 - accuracy: 0.9602\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 206s 2s/step - loss: 0.0640 - accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 204s 2s/step - loss: 0.0554 - accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 202s 2s/step - loss: 0.0627 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9313b9a160>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model.predict(test_generator)\n",
    "accuracy_score([0] * 250 + [1] * 250, predicts.reshape(-1) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
