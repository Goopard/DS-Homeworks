{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited tf.compat.v2.summary API due to missing TensorBoard installation\n",
      "Limited tf.summary API due to missing TensorBoard installation\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feedback.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line[:-1] for line in lines]\n",
    "    cols = lines[0].split(',')\n",
    "    lines = lines[1:]\n",
    "    lines = [line.split(',') for line in lines]\n",
    "    lines = [[*line[:4], \" \".join(line[4:])] for line in lines]\n",
    "\n",
    "dataset = pd.DataFrame(lines, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8342</td>\n",
       "      <td>Александр</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>\"6 входов  предохранитель\" \"искрит при включен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8342</td>\n",
       "      <td>Елена</td>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>\"Я являюсь пользователем Пилотов уже больше 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5311</td>\n",
       "      <td>Леонид</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>\"хорошо мелет\" \"маркий  остаются следы\" \"Испол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5311</td>\n",
       "      <td>Сергей</td>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>Компактная \"Не нашел\" \"Работает на ура. В инст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5311</td>\n",
       "      <td>Ольга</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>\"Цена и качество\" Нет \"В использовании 2 месяц...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating product_id       name        date  \\\n",
       "0      1       8342  Александр  2017-04-12   \n",
       "1      5       8342      Елена  2015-08-04   \n",
       "2      5       5311     Леонид  2017-07-16   \n",
       "3      4       5311     Сергей  2017-06-28   \n",
       "4      5       5311      Ольга  2017-01-21   \n",
       "\n",
       "                                            feedback  \n",
       "0  \"6 входов  предохранитель\" \"искрит при включен...  \n",
       "1  \"Я являюсь пользователем Пилотов уже больше 10...  \n",
       "2  \"хорошо мелет\" \"маркий  остаются следы\" \"Испол...  \n",
       "3  Компактная \"Не нашел\" \"Работает на ура. В инст...  \n",
       "4  \"Цена и качество\" Нет \"В использовании 2 месяц...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feedback(text: str):\n",
    "    text = text.replace(',', ' ')\n",
    "    return ''.join([c if c.isdigit() or c.isalpha() else ' ' for c in text.lower()])\n",
    "\n",
    "dataset['feedback'] = dataset['feedback'].apply(process_feedback)\n",
    "dataset['rating'] = dataset['rating'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8342</td>\n",
       "      <td>Александр</td>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>6 входов  предохранитель   искрит при включен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8342</td>\n",
       "      <td>Елена</td>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>я являюсь пользователем пилотов уже больше 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>Леонид</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>хорошо мелет   маркий  остаются следы   испол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>Сергей</td>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>компактная  не нашел   работает на ура  в инст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5311</td>\n",
       "      <td>Ольга</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>цена и качество  нет  в использовании 2 месяц...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating product_id       name        date  \\\n",
       "0     1.0       8342  Александр  2017-04-12   \n",
       "1     5.0       8342      Елена  2015-08-04   \n",
       "2     5.0       5311     Леонид  2017-07-16   \n",
       "3     4.0       5311     Сергей  2017-06-28   \n",
       "4     5.0       5311      Ольга  2017-01-21   \n",
       "\n",
       "                                            feedback  \n",
       "0   6 входов  предохранитель   искрит при включен...  \n",
       "1   я являюсь пользователем пилотов уже больше 10...  \n",
       "2   хорошо мелет   маркий  остаются следы   испол...  \n",
       "3  компактная  не нашел   работает на ура  в инст...  \n",
       "4   цена и качество  нет  в использовании 2 месяц...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset['feedback'], dataset['rating'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming + word encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "def stem(data):\n",
    "    stemmer = SnowballStemmer('russian')\n",
    "    return data.apply(lambda text: [stemmer.stem(word) for word in text.split(' ')])\n",
    "\n",
    "def clear_words(data):\n",
    "    return data.apply(lambda l: [word for word in l if word.isalpha()])\n",
    "\n",
    "def encode_words(train, test):\n",
    "    train = clear_words(train)\n",
    "    test = clear_words(test)\n",
    "    \n",
    "    words = reduce(lambda x, y: set(x).union(set(y)), chain(train, test))\n",
    "    words_map = {word: i + 2 for i, word in enumerate(words)}\n",
    "    print(len(words) + 2) \n",
    "    \n",
    "    mapping_func = lambda l: [words_map[word] for word in l] + [0]\n",
    "    return train.apply(mapping_func), test.apply(mapping_func)\n",
    "\n",
    "def equalize(train, test, length):\n",
    "    eq_func = lambda l: l[:length] if len(l) >= length else l + [1] * (length - len(l))\n",
    "    return train.apply(eq_func), test.apply(eq_func)\n",
    "\n",
    "def clear_zero_lengths(data):\n",
    "    return data.where(data.apply(len) != 0)\n",
    "\n",
    "def to_array(series):\n",
    "    return np.array(list(series.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem = stem(X_train)\n",
    "X_test_stem = stem(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25816\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded, X_test_encoded = encode_words(X_train_stem, X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f937c9aa978>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_encoded.apply(len).hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37.0, 36.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.apply(len).median(), X_test_encoded.apply(len).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr, X_test_tr = equalize(X_train_encoded, X_test_encoded, length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = to_array(X_train_tr)\n",
    "X_test_final = to_array(X_test_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM (continious target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11555 samples, validate on 1284 samples\n",
      "Epoch 1/4\n",
      "11555/11555 [==============================] - 86s 7ms/sample - loss: 2.0031 - mean_squared_error: 2.0031 - val_loss: 1.0864 - val_mean_squared_error: 1.0864\n",
      "Epoch 2/4\n",
      "11555/11555 [==============================] - 84s 7ms/sample - loss: 0.8968 - mean_squared_error: 0.8968 - val_loss: 0.8681 - val_mean_squared_error: 0.8681\n",
      "Epoch 3/4\n",
      "11555/11555 [==============================] - 83s 7ms/sample - loss: 0.5702 - mean_squared_error: 0.5702 - val_loss: 0.8785 - val_mean_squared_error: 0.8785\n",
      "Epoch 4/4\n",
      "11555/11555 [==============================] - 82s 7ms/sample - loss: 0.4433 - mean_squared_error: 0.4433 - val_loss: 0.8592 - val_mean_squared_error: 0.8592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f761f153c50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(25816, 128))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.005), loss=tf.keras.losses.mean_squared_error, metrics=[tf.keras.metrics.mean_squared_error])\n",
    "model.fit(X_train_final, y_train, batch_size=128, epochs=4, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129527709337447"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_final)\n",
    "mean_squared_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.26      0.35       521\n",
      "           2       0.20      0.33      0.25       314\n",
      "           3       0.20      0.23      0.22       447\n",
      "           4       0.26      0.34      0.29       924\n",
      "           5       0.83      0.77      0.80      3297\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      5503\n",
      "   macro avg       0.41      0.39      0.38      5503\n",
      "weighted avg       0.62      0.58      0.59      5503\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5785934944575686"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test.round().astype('int'), predictions.round().astype('int')))\n",
    "accuracy_score(y_test.round().astype('int'), predictions.round().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM (multiclass target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train_ohe = OneHotEncoder().fit_transform(y_train.round().astype('int').reshape(-1, 1)).todense()\n",
    "y_test_ohe = OneHotEncoder().fit_transform(y_test.round().astype('int').reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11555 samples, validate on 1284 samples\n",
      "Epoch 1/3\n",
      "11555/11555 [==============================] - 84s 7ms/sample - loss: 1.0461 - accuracy: 0.6168 - val_loss: 0.8824 - val_accuracy: 0.6542\n",
      "Epoch 2/3\n",
      "11555/11555 [==============================] - 83s 7ms/sample - loss: 0.7723 - accuracy: 0.7032 - val_loss: 0.8920 - val_accuracy: 0.6480\n",
      "Epoch 3/3\n",
      "11555/11555 [==============================] - 83s 7ms/sample - loss: 0.5872 - accuracy: 0.7797 - val_loss: 0.9577 - val_accuracy: 0.6410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f760fcdcb70>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(28557, 128))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.005), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.fit(X_train_final, y_train_ohe, batch_size=128, epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_final).argmax(axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.51      0.50       521\n",
      "           2       0.22      0.06      0.09       314\n",
      "           3       0.27      0.13      0.17       447\n",
      "           4       0.31      0.47      0.37       924\n",
      "           5       0.81      0.80      0.80      3297\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      5503\n",
      "   macro avg       0.42      0.39      0.39      5503\n",
      "weighted avg       0.62      0.62      0.61      5503\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6180265309831001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test.round().astype('int'), predictions))\n",
    "accuracy_score(y_test.round().astype('int'), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM (binary target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = (y_train.round() > 3).astype('int')\n",
    "y_test_bin = (y_test.round() > 3).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10271 samples, validate on 2568 samples\n",
      "Epoch 1/3\n",
      "10271/10271 [==============================] - 98s 10ms/sample - loss: 0.4115 - accuracy: 0.8258 - val_loss: 0.3358 - val_accuracy: 0.8575\n",
      "Epoch 2/3\n",
      "10271/10271 [==============================] - 100s 10ms/sample - loss: 0.2275 - accuracy: 0.9170 - val_loss: 0.3436 - val_accuracy: 0.8621\n",
      "Epoch 3/3\n",
      "10271/10271 [==============================] - 100s 10ms/sample - loss: 0.1196 - accuracy: 0.9605 - val_loss: 0.4021 - val_accuracy: 0.8567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f75f0c28e80>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(28557, 128))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "model.fit(X_train_final, y_train_bin, batch_size=64, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66      1282\n",
      "           1       0.88      0.95      0.91      4221\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5503\n",
      "   macro avg       0.82      0.76      0.78      5503\n",
      "weighted avg       0.85      0.86      0.85      5503\n",
      "\n",
      "0.8971338242300124\n",
      "0.8597128838815191\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bin, predictions > 0.5))\n",
    "print(roc_auc_score(y_test_bin, predictions))\n",
    "print(accuracy_score(y_test_bin, predictions > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext model with multiclass target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def get_row_ngrams(row, ngram_range):\n",
    "    return set(zip(*[row[i:] for i in range(ngram_range)]))\n",
    "\n",
    "\n",
    "def get_all_ngrams(dataset, ngram_range):\n",
    "    ngramed_dataset = map(partial(get_row_ngrams, ngram_range=ngram_range), dataset)\n",
    "    return reduce(lambda x, y: x.union(y), ngramed_dataset)\n",
    "\n",
    "\n",
    "def build_ngram_mapping(train, test, ngram_range):\n",
    "    max_features = max(train.apply(lambda x: max(x)).max(), test.apply(lambda x: max(x)).max())\n",
    "    train_ngrams = get_all_ngrams(train, ngram_range)\n",
    "    test_ngrams = get_all_ngrams(test, ngram_range)\n",
    "    return {ngram: i + max_features + 1 for i, ngram in enumerate(train_ngrams.union(test_ngrams))}\n",
    "\n",
    "\n",
    "def add_ngrams_to_row(row, ngram_mapping, ngram_range):\n",
    "    existing_ngrams = get_row_ngrams(row, ngram_range)\n",
    "    return list(row) + [ngram_mapping[ngram] for ngram in existing_ngrams]\n",
    "\n",
    "\n",
    "def add_ngrams_to_dataset(dataset, ngram_mapping, ngram_range):\n",
    "    return dataset.apply(lambda row: add_ngrams_to_row(row, ngram_mapping, ngram_range))\n",
    "\n",
    "\n",
    "def add_ngrams(train, test, ngram_range=2):\n",
    "    ngram_mapping = build_ngram_mapping(train, test, ngram_range)\n",
    "    return add_ngrams_to_dataset(train, ngram_mapping, ngram_range), add_ngrams_to_dataset(test, ngram_mapping, ngram_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_ngrams = pd.Series(list(pad_sequences(X_train_encoded, maxlen=128)))\n",
    "X_test_for_ngrams = pd.Series(list(pad_sequences(X_test_encoded, maxlen=128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ngramed, X_test_ngramed = add_ngrams(X_train_for_ngrams, X_test_for_ngrams, ngram_range=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ngramed = pad_sequences(X_train_ngramed, maxlen=256)\n",
    "X_test_ngramed = pad_sequences(X_test_ngramed, maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377631"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = max(X_train_ngramed.max(), X_test_ngramed.max()) + 1\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10271 samples, validate on 2568 samples\n",
      "Epoch 1/4\n",
      "10271/10271 [==============================] - 50s 5ms/sample - loss: 1.1826 - accuracy: 0.5849 - val_loss: 1.0222 - val_accuracy: 0.6121\n",
      "Epoch 2/4\n",
      "10271/10271 [==============================] - 50s 5ms/sample - loss: 0.7723 - accuracy: 0.7019 - val_loss: 0.8307 - val_accuracy: 0.6686\n",
      "Epoch 3/4\n",
      "10271/10271 [==============================] - 50s 5ms/sample - loss: 0.3723 - accuracy: 0.8933 - val_loss: 0.8206 - val_accuracy: 0.6807\n",
      "Epoch 4/4\n",
      "10271/10271 [==============================] - 49s 5ms/sample - loss: 0.1625 - accuracy: 0.9709 - val_loss: 0.8445 - val_accuracy: 0.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93721e55c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=256))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_ngramed, y_train_ohe, batch_size=128, epochs=4, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.50      0.54       527\n",
      "           2       0.28      0.06      0.10       311\n",
      "           3       0.30      0.24      0.27       449\n",
      "           4       0.42      0.39      0.40       904\n",
      "           5       0.80      0.91      0.85      3312\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5503\n",
      "   macro avg       0.47      0.42      0.43      5503\n",
      "weighted avg       0.64      0.68      0.66      5503\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6821733599854625"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_ngramed).argmax(axis=1) + 1\n",
    "print(classification_report(y_test.round().astype('int'), predictions))\n",
    "accuracy_score(y_test.round().astype('int'), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ngramed, X_test_ngramed = add_ngrams(X_train_for_ngrams, X_test_for_ngrams, ngram_range=3)\n",
    "X_train_ngramed = pad_sequences(X_train_ngramed, maxlen=512)\n",
    "X_test_ngramed = pad_sequences(X_test_ngramed, maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710743"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = max(X_train_ngramed.max(), X_test_ngramed.max()) + 1\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10271 samples, validate on 2568 samples\n",
      "Epoch 1/6\n",
      "10271/10271 [==============================] - 93s 9ms/sample - loss: 1.2310 - accuracy: 0.5863 - val_loss: 1.1565 - val_accuracy: 0.6083\n",
      "Epoch 2/6\n",
      "10271/10271 [==============================] - 94s 9ms/sample - loss: 1.1464 - accuracy: 0.5922 - val_loss: 1.1086 - val_accuracy: 0.6083\n",
      "Epoch 3/6\n",
      "10271/10271 [==============================] - 93s 9ms/sample - loss: 0.9977 - accuracy: 0.6097 - val_loss: 1.0060 - val_accuracy: 0.6180\n",
      "Epoch 4/6\n",
      "10271/10271 [==============================] - 93s 9ms/sample - loss: 0.7613 - accuracy: 0.7071 - val_loss: 0.9455 - val_accuracy: 0.6293\n",
      "Epoch 5/6\n",
      "10271/10271 [==============================] - 92s 9ms/sample - loss: 0.5426 - accuracy: 0.8201 - val_loss: 0.8849 - val_accuracy: 0.6515\n",
      "Epoch 6/6\n",
      "10271/10271 [==============================] - 92s 9ms/sample - loss: 0.3820 - accuracy: 0.9008 - val_loss: 0.8769 - val_accuracy: 0.6550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93264c2be0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=512))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(lr=0.005), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_ngramed, y_train_ohe, batch_size=128, epochs=6, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.36      0.42       527\n",
      "           2       0.00      0.00      0.00       311\n",
      "           3       0.31      0.08      0.12       449\n",
      "           4       0.44      0.22      0.30       904\n",
      "           5       0.70      0.96      0.81      3312\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5503\n",
      "   macro avg       0.39      0.32      0.33      5503\n",
      "weighted avg       0.56      0.65      0.58      5503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6538251862620389"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_ngramed).argmax(axis=1) + 1\n",
    "print(classification_report(y_test.round().astype('int'), predictions))\n",
    "accuracy_score(y_test.round().astype('int'), predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
