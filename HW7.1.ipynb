{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, recall_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('titanic.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211,3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0,9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0      29    0.0    0.0   24160  211,3375       B5        S    2    NaN   \n",
       "1  0,9167    1.0    2.0  113781  151,5500  C22 C26        S   11    NaN   \n",
       "2       2    1.0    2.0  113781  151,5500  C22 C26        S  NaN    NaN   \n",
       "3      30    1.0    2.0  113781  151,5500  C22 C26        S  NaN  135.0   \n",
       "4      25    1.0    2.0  113781  151,5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['sex'] = pdf['sex'].map({'female': 1.0, 'male': 0.0})\n",
    "pdf['embarked'] = pdf['embarked'].map({'C': 0.0, 'Q': 1.0, 'S': 2.0})\n",
    "pdf['age'] = pdf['age'].apply(lambda val: str(val).replace(',', '.')).astype(float)\n",
    "pdf['fare'] = pdf['fare'].apply(lambda val: str(val).replace(',', '.')).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          1\n",
       "survived        1\n",
       "name            1\n",
       "sex             1\n",
       "age           264\n",
       "sibsp           1\n",
       "parch           1\n",
       "ticket          1\n",
       "fare            2\n",
       "cabin        1015\n",
       "embarked        3\n",
       "boat          824\n",
       "body         1189\n",
       "home.dest     565\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdf.dropna(subset=['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4437aaea58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf['age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff914649630>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEV1JREFUeJzt3X+s3XV9x/Hne1R+SB0t4G6attnF2GiInYo3UINZTunmChrLH2g0jVTTpf+gw9Flli0Z2fbHMBkyIAtZY5k1aayKLm2QzXWFk8U/qFJBWqiMKyvSplCRUnf9MdftvT/Op82xFku/33vPuT2f5yM5ud/v5/v5ns/nfTnc1/l+zo9GZiJJqs9vDHsCkqThMAAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlZoz7An8OpdeemmOj483Pv8nP/kJF1544fRNaBaz1tFVU7011QozV+/u3btfysw3nq7frA6A8fFxHn300cbnd7tdOp3O9E1oFrPW0VVTvTXVCjNXb0Q891r6uQQkSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVmtWfBG5rz8GjfGzD1wc+7v7b3zfwMSXpTHkFIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTptAETEfRFxOCL29rVdHBE7IuKZ8nN+aY+IuDsiJiPiiYi4ou+cNaX/MxGxZmbKkSS9Vq/lCuDzwMqT2jYAOzNzCbCz7ANcCywpt3XAvdALDOA24CrgSuC246EhSRqO0wZAZv478PJJzauAzWV7M3B9X/sXsucRYF5ELAD+ANiRmS9n5hFgB78aKpKkAWr6ZXBjmXmobL8AjJXthcDzff0OlLZXa/8VEbGO3tUDY2NjdLvdhlOEsQtg/dJjjc9vqs2cm5qamhrKuMNQU61QV7011QrDr7f1t4FmZkZETsdkyv1tBDYCTExMZKfTaXxf92zZxh17Bv+Fp/tXdwY+Zrfbpc3v6mxSU61QV7011QrDr7fpu4BeLEs7lJ+HS/tBYHFfv0Wl7dXaJUlD0jQAtgPH38mzBtjW135jeTfQMuBoWSr6BvDeiJhfXvx9b2mTJA3JaddHIuKLQAe4NCIO0Hs3z+3AlyNiLfAc8KHS/UHgOmAS+CnwcYDMfDki/hr4dun3V5l58gvLkqQBOm0AZOZHXuXQilP0TeCmV7mf+4D7zmh2kqQZ4yeBJalSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIq1SoAIuKPI+LJiNgbEV+MiPMj4rKI2BURkxHxpYg4t/Q9r+xPluPj01GAJKmZxgEQEQuBPwImMvNtwDnAh4HPAHdm5puBI8Dacspa4Ehpv7P0kyQNSdsloDnABRExB3g9cAi4Bri/HN8MXF+2V5V9yvEVEREtx5ckNdQ4ADLzIPC3wA/o/eE/CuwGXsnMY6XbAWBh2V4IPF/OPVb6X9J0fElSO3OanhgR8+k9q78MeAX4CrCy7YQiYh2wDmBsbIxut9v4vsYugPVLj52+4zRrM+empqamhjLuMNRUK9RVb021wvDrbRwAwO8B/5mZPwSIiK8BVwPzImJOeZa/CDhY+h8EFgMHypLRRcCPTr7TzNwIbASYmJjITqfTeIL3bNnGHXvalNjM/tWdgY/Z7XZp87s6m9RUK9RVb021wvDrbfMawA+AZRHx+rKWvwJ4CngYuKH0WQNsK9vbyz7l+EOZmS3GlyS10OY1gF30Xsz9DrCn3NdG4NPALRExSW+Nf1M5ZRNwSWm/BdjQYt6SpJZarY9k5m3AbSc1PwtceYq+Pwc+2GY8SdL08ZPAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVKtAiAi5kXE/RHxvYjYFxHvjoiLI2JHRDxTfs4vfSMi7o6IyYh4IiKumJ4SJElNtL0CuAv4l8x8K/B2YB+wAdiZmUuAnWUf4FpgSbmtA+5tObYkqYXGARARFwG/C2wCyMxfZOYrwCpgc+m2Gbi+bK8CvpA9jwDzImJB45lLklppcwVwGfBD4B8j4rGI+FxEXAiMZeah0ucFYKxsLwSe7zv/QGmTJA1BZGazEyMmgEeAqzNzV0TcBfwY+GRmzuvrdyQz50fEA8DtmfnN0r4T+HRmPnrS/a6jt0TE2NjYu7Zu3dpofgCHXz7Kiz9rfHpjSxdeNPAxp6ammDt37sDHHYaaaoW66q2pVpi5epcvX747MydO129OizEOAAcyc1fZv5/eev+LEbEgMw+VJZ7D5fhBYHHf+YtK2y/JzI3ARoCJiYnsdDqNJ3jPlm3csadNic3sX90Z+Jjdbpc2v6uzSU21Ql311lQrDL/exktAmfkC8HxEvKU0rQCeArYDa0rbGmBb2d4O3FjeDbQMONq3VCRJGrC2T48/CWyJiHOBZ4GP0wuVL0fEWuA54EOl74PAdcAk8NPSV5I0JK0CIDMfB061zrTiFH0TuKnNeJKk6eMngSWpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlWgdARJwTEY9FxANl/7KI2BURkxHxpYg4t7SfV/Yny/HxtmNLkpqbjiuAm4F9ffufAe7MzDcDR4C1pX0tcKS031n6SZKGpFUARMQi4H3A58p+ANcA95cum4Hry/aqsk85vqL0lyQNQWRm85Mj7gf+BngD8CfAx4BHyrN8ImIx8M+Z+baI2AuszMwD5dj3gasy86WT7nMdsA5gbGzsXVu3bm08v8MvH+XFnzU+vbGlCy8a+JhTU1PMnTt34OMOQ021Ql311lQrzFy9y5cv352ZE6frN6fpABHxfuBwZu6OiE7T+zlZZm4ENgJMTExkp9P8ru/Zso079jQusbH9qzsDH7Pb7dLmd3U2qalWqKvemmqF4dfb5q/j1cAHIuI64HzgN4G7gHkRMSczjwGLgIOl/0FgMXAgIuYAFwE/ajG+JKmFxq8BZOatmbkoM8eBDwMPZeZq4GHghtJtDbCtbG8v+5TjD2Wb9SdJUisz8TmATwO3RMQkcAmwqbRvAi4p7bcAG2ZgbEnSazQtC+SZ2QW6ZftZ4MpT9Pk58MHpGE+S1J6fBJakShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqlTjAIiIxRHxcEQ8FRFPRsTNpf3iiNgREc+Un/NLe0TE3RExGRFPRMQV01WEJOnMtbkCOAasz8zLgWXATRFxObAB2JmZS4CdZR/gWmBJua0D7m0xtiSppcYBkJmHMvM7Zfu/gH3AQmAVsLl02wxcX7ZXAV/InkeAeRGxoPHMJUmtTMtrABExDrwT2AWMZeahcugFYKxsLwSe7zvtQGmTJA3BnLZ3EBFzga8Cn8rMH0fEiWOZmRGRZ3h/6+gtETE2Nka32208t7ELYP3SY43Pb6rNnJuampoayrjDUFOtUFe9NdUKw6+3VQBExOvo/fHfkplfK80vRsSCzDxUlngOl/aDwOK+0xeVtl+SmRuBjQATExPZ6XQaz++eLdu4Y0/rjDtj+1d3Bj5mt9ulze/qbFJTrVBXvTXVCsOvt827gALYBOzLzM/2HdoOrCnba4Btfe03lncDLQOO9i0VSZIGrM3T46uBjwJ7IuLx0vZnwO3AlyNiLfAc8KFy7EHgOmAS+Cnw8RZjS5JaahwAmflNIF7l8IpT9E/gpqbjSZKml58ElqRKGQCSVCkDQJIqZQBIUqUG/yb5Coxv+PrAx1y/9BidgY8q6WzmFYAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpeYMewKaPuMbvj60sfff/r6hjS2pGa8AJKlSBoAkVcoAkKRKDfw1gIhYCdwFnAN8LjNvH/QcNDp83UNqbqABEBHnAH8P/D5wAPh2RGzPzKcGOQ9pOgwqfNYvPcbH+sYyeDRdBr0EdCUwmZnPZuYvgK3AqgHPQZLE4JeAFgLP9+0fAK4a8Bw0Awa5FHPyM2Jppsz04/rXPZYHcaUXmTnjg5wYLOIGYGVm/mHZ/yhwVWZ+oq/POmBd2X0L8HSLIS8FXmpx/tnEWkdXTfXWVCvMXL2/nZlvPF2nQV8BHAQW9+0vKm0nZOZGYON0DBYRj2bmxHTc12xnraOrpnprqhWGX++gXwP4NrAkIi6LiHOBDwPbBzwHSRIDvgLIzGMR8QngG/TeBnpfZj45yDlIknoG/jmAzHwQeHBAw03LUtJZwlpHV0311lQrDLnegb4ILEmaPfwqCEmq1EgGQESsjIinI2IyIjYMez7TISLui4jDEbG3r+3iiNgREc+Un/NLe0TE3aX+JyLiiuHN/MxFxOKIeDginoqIJyPi5tI+cvVGxPkR8a2I+G6p9S9L+2URsavU9KXypgki4ryyP1mOjw9z/k1ExDkR8VhEPFD2R7nW/RGxJyIej4hHS9useRyPXAD0fd3EtcDlwEci4vLhzmpafB5YeVLbBmBnZi4BdpZ96NW+pNzWAfcOaI7T5RiwPjMvB5YBN5X/hqNY738D12Tm24F3ACsjYhnwGeDOzHwzcARYW/qvBY6U9jtLv7PNzcC+vv1RrhVgeWa+o+/tnrPncZyZI3UD3g18o2//VuDWYc9rmmobB/b27T8NLCjbC4Cny/Y/AB85Vb+z8QZso/f9USNdL/B64Dv0Ph3/EjCntJ94TNN7B927y/ac0i+GPfczqHERvT961wAPADGqtZZ57wcuPalt1jyOR+4KgFN/3cTCIc1lpo1l5qGy/QIwVrZH5ndQLvvfCexiROstSyKPA4eBHcD3gVcy81jp0l/PiVrL8aPAJYOdcSt/B/wp8H9l/xJGt1aABP41InaXbzmAWfQ49p+EHBGZmRExUm/pioi5wFeBT2XmjyPixLFRqjcz/xd4R0TMA/4JeOuQpzQjIuL9wOHM3B0RnWHPZ0Dek5kHI+K3gB0R8b3+g8N+HI/iFcBpv25ihLwYEQsAys/Dpf2s/x1ExOvo/fHfkplfK80jWy9AZr4CPExvGWReRBx/gtZfz4lay/GLgB8NeKpNXQ18ICL20/sm4Gvo/dsgo1grAJl5sPw8TC/cr2QWPY5HMQBq+rqJ7cCasr2G3lr58fYby7sKlgFH+y45Z73oPdXfBOzLzM/2HRq5eiPijeWZPxFxAb3XOvbRC4IbSreTaz3+O7gBeCjLgvFsl5m3ZuaizByn9//lQ5m5mhGsFSAiLoyINxzfBt4L7GU2PY6H/SLJDL3wch3wH/TWUv982POZppq+CBwC/ofe2uBaeuuhO4FngH8DLi59g947ob4P7AEmhj3/M6z1PfTWTp8AHi+360axXuB3gMdKrXuBvyjtbwK+BUwCXwHOK+3nl/3JcvxNw66hYd0d4IFRrrXU9d1ye/L436LZ9Dj2k8CSVKlRXAKSJL0GBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZX6f7izv1yXnw98AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf['fare'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing features analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass\n",
       "1.0    0.619195\n",
       "2.0    0.429603\n",
       "3.0    0.255289\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['pclass'])['survived'].sum() / pdf.groupby(['pclass']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "female    0.727468\n",
       "male      0.190985\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sex'])['survived'].sum() / pdf.groupby(['sex']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex     pclass\n",
       "female  1.0       0.965278\n",
       "        2.0       0.886792\n",
       "        3.0       0.490741\n",
       "male    1.0       0.340782\n",
       "        2.0       0.146199\n",
       "        3.0       0.152130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sex', 'pclass'])['survived'].sum() / pdf.groupby(['sex', 'pclass']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked\n",
       "C    0.555556\n",
       "Q    0.357724\n",
       "S    0.332604\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['embarked'])['survived'].sum() / pdf.groupby(['embarked']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parch\n",
       "0.0    0.335329\n",
       "1.0    0.588235\n",
       "2.0    0.504425\n",
       "3.0    0.625000\n",
       "4.0    0.166667\n",
       "5.0    0.166667\n",
       "6.0    0.000000\n",
       "9.0    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['parch'])['survived'].sum() / pdf.groupby(['parch']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boated\n",
       "0.0    0.027947\n",
       "1.0    0.981481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['boated'] = (~pdf['boat'].isna()).astype(float)\n",
    "pdf.groupby(['boated'])['survived'].sum() / pdf.groupby(['boated']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex     pclass  boated\n",
       "female  1.0     0.0       0.166667\n",
       "                1.0       1.000000\n",
       "        2.0     0.0       0.400000\n",
       "                1.0       1.000000\n",
       "        3.0     0.0       0.099174\n",
       "                1.0       0.989474\n",
       "male    1.0     0.0       0.000000\n",
       "                1.0       0.968254\n",
       "        2.0     0.0       0.000000\n",
       "                1.0       0.961538\n",
       "        3.0     0.0       0.004819\n",
       "                1.0       0.935897\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sex', 'pclass', 'boated'])['survived'].sum() / pdf.groupby(['sex', 'pclass', 'boated']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sibsp\n",
       "0.0    0.346801\n",
       "1.0    0.510972\n",
       "2.0    0.452381\n",
       "3.0    0.300000\n",
       "4.0    0.136364\n",
       "5.0    0.000000\n",
       "8.0    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sibsp'])['survived'].sum() / pdf.groupby(['sibsp']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['boated', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked', 'fare']\n",
    "pdf_clear = pdf[features + ['survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(pdf_clear[features], pdf_clear['survived'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=features)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=features)\n",
    "y_train = pd.Series(y_train.values)\n",
    "y_test = pd.Series(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFLogReg:\n",
    "    def __init__(self, n_iter=100, learning_rate=0.05):\n",
    "        self.n_iter = n_iter\n",
    "        self.lr = learning_rate\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "    \n",
    "    def _predict(self, X):\n",
    "        return tf.nn.sigmoid(tf.matmul(X.values, self.W) + self.b)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._predict(X).numpy()\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logit = self._predict(X)\n",
    "            loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=np.array([y]).T))\n",
    "            W_grad, b_grad = tape.gradient(loss, [self.W, self.b])\n",
    "        return W_grad, b_grad\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.W = tf.Variable(tf.zeros([X_train.shape[1], 1], dtype=X.values.dtype))\n",
    "        self.b = tf.Variable(tf.zeros([1], dtype=X.values.dtype))\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            W_grad, b_grad = self.train_step(X, y)\n",
    "\n",
    "            self.W.assign_sub(self.lr * W_grad)\n",
    "            self.b.assign_sub(self.lr * b_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try two different approaches of NaN-dealing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       425\n",
      "         1.0       0.97      0.91      0.94       230\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       655\n",
      "   macro avg       0.96      0.95      0.95       655\n",
      "weighted avg       0.96      0.96      0.96       655\n",
      "\n",
      "ROC-AUC score: 0.9878925831202047\n"
     ]
    }
   ],
   "source": [
    "model = TFLogReg(learning_rate=0.1, n_iter=100)\n",
    "model.fit(X_train.fillna(0.0), y_train)\n",
    "y_pred = model.predict(X_test.fillna(0.0))\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_mean(df):\n",
    "    return df.fillna({col: df[col].mean() for col in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97       425\n",
      "         1.0       0.97      0.91      0.94       230\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       655\n",
      "   macro avg       0.96      0.95      0.95       655\n",
      "weighted avg       0.96      0.96      0.96       655\n",
      "\n",
      "ROC-AUC score: 0.9878721227621483\n"
     ]
    }
   ],
   "source": [
    "model = TFLogReg(learning_rate=0.1, n_iter=100)\n",
    "model.fit(fillna_mean(X_train), y_train)\n",
    "y_pred = model.predict(fillna_mean(X_test))\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_keras(X_train, y_train, X_test, n_iter=100, learning_rate=0.05, batch_size=50):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=n_iter)\n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "654/654 [==============================] - 0s 458us/sample - loss: 0.6874 - accuracy: 0.6468\n",
      "Epoch 2/10\n",
      "654/654 [==============================] - 0s 78us/sample - loss: 0.2900 - accuracy: 0.9602\n",
      "Epoch 3/10\n",
      "654/654 [==============================] - 0s 80us/sample - loss: 0.1953 - accuracy: 0.9771\n",
      "Epoch 4/10\n",
      "654/654 [==============================] - 0s 96us/sample - loss: 0.1569 - accuracy: 0.9801\n",
      "Epoch 5/10\n",
      "654/654 [==============================] - 0s 104us/sample - loss: 0.1359 - accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "654/654 [==============================] - 0s 114us/sample - loss: 0.1228 - accuracy: 0.9801\n",
      "Epoch 7/10\n",
      "654/654 [==============================] - 0s 113us/sample - loss: 0.1139 - accuracy: 0.9801\n",
      "Epoch 8/10\n",
      "654/654 [==============================] - 0s 101us/sample - loss: 0.1073 - accuracy: 0.9801\n",
      "Epoch 9/10\n",
      "654/654 [==============================] - 0s 94us/sample - loss: 0.1025 - accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "654/654 [==============================] - 0s 101us/sample - loss: 0.0986 - accuracy: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       425\n",
      "         1.0       0.98      0.93      0.96       230\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       655\n",
      "   macro avg       0.97      0.96      0.97       655\n",
      "weighted avg       0.97      0.97      0.97       655\n",
      "\n",
      "ROC-AUC score: 0.9910843989769821\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras(X_train.fillna(0.0), y_train, X_test.fillna(0.0), n_iter=10, learning_rate=0.1, batch_size=50)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "654/654 [==============================] - 0s 491us/sample - loss: 0.4848 - accuracy: 0.7997\n",
      "Epoch 2/10\n",
      "654/654 [==============================] - 0s 80us/sample - loss: 0.2528 - accuracy: 0.9602\n",
      "Epoch 3/10\n",
      "654/654 [==============================] - 0s 77us/sample - loss: 0.1810 - accuracy: 0.9771\n",
      "Epoch 4/10\n",
      "654/654 [==============================] - 0s 63us/sample - loss: 0.1487 - accuracy: 0.9786\n",
      "Epoch 5/10\n",
      "654/654 [==============================] - 0s 74us/sample - loss: 0.1306 - accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "654/654 [==============================] - 0s 106us/sample - loss: 0.1190 - accuracy: 0.9801\n",
      "Epoch 7/10\n",
      "654/654 [==============================] - 0s 108us/sample - loss: 0.1110 - accuracy: 0.9801\n",
      "Epoch 8/10\n",
      "654/654 [==============================] - 0s 116us/sample - loss: 0.1050 - accuracy: 0.9801\n",
      "Epoch 9/10\n",
      "654/654 [==============================] - 0s 93us/sample - loss: 0.1008 - accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "654/654 [==============================] - 0s 103us/sample - loss: 0.0972 - accuracy: 0.9801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       425\n",
      "         1.0       0.98      0.93      0.96       230\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       655\n",
      "   macro avg       0.97      0.96      0.97       655\n",
      "weighted avg       0.97      0.97      0.97       655\n",
      "\n",
      "ROC-AUC score: 0.9911662404092072\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras(fillna_mean(X_train), y_train, fillna_mean(X_test), n_iter=10, learning_rate=0.1, batch_size=50)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras model is a bit better, but still the results are almost the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thyroid Disease DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already done a full EDA of this dataset in HW3, so we will just be using preprocessed train and test sets from that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('thyroid_train.csv')\n",
    "test = pd.read_csv('thyroid_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSH</th>\n",
       "      <th>TT4</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>T4U</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.178313</td>\n",
       "      <td>-0.984492</td>\n",
       "      <td>0</td>\n",
       "      <td>1.176381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.165593</td>\n",
       "      <td>-0.070426</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.662252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.093509</td>\n",
       "      <td>-0.896034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.106229</td>\n",
       "      <td>0.047518</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.554097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166441</td>\n",
       "      <td>1.226959</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TSH       TT4  on_thyroxine       T4U  Class\n",
       "0 -0.178313 -0.984492             0  1.176381      0\n",
       "1 -0.165593 -0.070426             0 -0.662252      0\n",
       "2 -0.093509 -0.896034             0  0.257065      0\n",
       "3 -0.106229  0.047518             0 -0.554097      0\n",
       "4 -0.166441  1.226959             0  0.202987      0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2444\n",
       "1     136\n",
       "2      60\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1037\n",
       "1      58\n",
       "2      37\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSH             0\n",
       "TT4             0\n",
       "on_thyroxine    0\n",
       "T4U             0\n",
       "Class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSH             0\n",
       "TT4             0\n",
       "on_thyroxine    0\n",
       "T4U             0\n",
       "Class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TSH', 'TT4', 'on_thyroxine', 'T4U']\n",
    "X_train = train[cols]\n",
    "X_test = test[cols]\n",
    "y_train = train['Class']\n",
    "y_test = test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFLogRegMulticlass(TFLogReg):\n",
    "    def _predict(self, X):\n",
    "        return tf.nn.softmax(tf.matmul(X, self.W) + self.b)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return tf.argmax(self._predict(X), 1).numpy()\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logit = self._predict(X)\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y))\n",
    "            W_grad, b_grad = tape.gradient(loss, [self.W, self.b])\n",
    "        return W_grad, b_grad\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X, y = BorderlineSMOTE().fit_resample(X, y)\n",
    "        y = OneHotEncoder().fit_transform(y.reshape(-1, 1)).todense()\n",
    "        \n",
    "        self.W = tf.Variable(tf.zeros([X_train.shape[1], 3], dtype=X.dtype))\n",
    "        self.b = tf.Variable(tf.zeros([3], dtype=X.dtype))\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            W_grad, b_grad = self.train_step(X, y)            \n",
    "            self.W.assign_sub(self.lr * W_grad)\n",
    "            self.b.assign_sub(self.lr * b_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1037\n",
      "           1       0.77      1.00      0.87        58\n",
      "           2       0.84      0.97      0.90        37\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1132\n",
      "   macro avg       0.87      0.98      0.92      1132\n",
      "weighted avg       0.98      0.98      0.98      1132\n",
      "\n",
      "0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "model = TFLogRegMulticlass(learning_rate=20, n_iter=300)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test.values)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred, average='macro', labels=[1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_keras_multiclass(X_train, y_train, X_test, n_iter=100, learning_rate=0.05):\n",
    "    X_train, y_train = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
    "    y_train = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=3, input_dim=X_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=n_iter)\n",
    "    return np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7332/7332 [==============================] - 1s 126us/sample - loss: 0.3252 - accuracy: 0.9343\n",
      "Epoch 2/50\n",
      "7332/7332 [==============================] - 1s 84us/sample - loss: 0.2000 - accuracy: 0.9739\n",
      "Epoch 3/50\n",
      "7332/7332 [==============================] - 1s 87us/sample - loss: 0.1807 - accuracy: 0.9783\n",
      "Epoch 4/50\n",
      "7332/7332 [==============================] - 1s 81us/sample - loss: 0.1719 - accuracy: 0.9802\n",
      "Epoch 5/50\n",
      "7332/7332 [==============================] - 1s 81us/sample - loss: 0.1667 - accuracy: 0.9806\n",
      "Epoch 6/50\n",
      "7332/7332 [==============================] - 1s 84us/sample - loss: 0.1637 - accuracy: 0.9805\n",
      "Epoch 7/50\n",
      "7332/7332 [==============================] - 1s 88us/sample - loss: 0.1618 - accuracy: 0.9812\n",
      "Epoch 8/50\n",
      "7332/7332 [==============================] - 1s 95us/sample - loss: 0.1603 - accuracy: 0.9820\n",
      "Epoch 9/50\n",
      "7332/7332 [==============================] - 1s 93us/sample - loss: 0.1598 - accuracy: 0.9823\n",
      "Epoch 10/50\n",
      "7332/7332 [==============================] - 1s 92us/sample - loss: 0.1585 - accuracy: 0.9824\n",
      "Epoch 11/50\n",
      "7332/7332 [==============================] - 1s 95us/sample - loss: 0.1581 - accuracy: 0.9824\n",
      "Epoch 12/50\n",
      "7332/7332 [==============================] - 1s 87us/sample - loss: 0.1572 - accuracy: 0.9831\n",
      "Epoch 13/50\n",
      "7332/7332 [==============================] - 1s 92us/sample - loss: 0.1573 - accuracy: 0.9828\n",
      "Epoch 14/50\n",
      "7332/7332 [==============================] - 1s 92us/sample - loss: 0.1564 - accuracy: 0.9834\n",
      "Epoch 15/50\n",
      "7332/7332 [==============================] - 1s 89us/sample - loss: 0.1558 - accuracy: 0.9836\n",
      "Epoch 16/50\n",
      "7332/7332 [==============================] - 1s 88us/sample - loss: 0.1559 - accuracy: 0.9827\n",
      "Epoch 17/50\n",
      "7332/7332 [==============================] - 1s 97us/sample - loss: 0.1559 - accuracy: 0.9834\n",
      "Epoch 18/50\n",
      "7332/7332 [==============================] - 1s 88us/sample - loss: 0.1558 - accuracy: 0.9821\n",
      "Epoch 19/50\n",
      "7332/7332 [==============================] - 1s 91us/sample - loss: 0.1555 - accuracy: 0.9832\n",
      "Epoch 20/50\n",
      "7332/7332 [==============================] - 1s 99us/sample - loss: 0.1576 - accuracy: 0.9817\n",
      "Epoch 21/50\n",
      "7332/7332 [==============================] - 1s 90us/sample - loss: 0.1552 - accuracy: 0.9835\n",
      "Epoch 22/50\n",
      "7332/7332 [==============================] - 1s 95us/sample - loss: 0.1556 - accuracy: 0.9834\n",
      "Epoch 23/50\n",
      "7332/7332 [==============================] - 1s 89us/sample - loss: 0.1556 - accuracy: 0.9840\n",
      "Epoch 24/50\n",
      "7332/7332 [==============================] - 1s 96us/sample - loss: 0.1549 - accuracy: 0.9839\n",
      "Epoch 25/50\n",
      "7332/7332 [==============================] - 1s 94us/sample - loss: 0.1544 - accuracy: 0.9846\n",
      "Epoch 26/50\n",
      "7332/7332 [==============================] - 1s 90us/sample - loss: 0.1549 - accuracy: 0.9842\n",
      "Epoch 27/50\n",
      "7332/7332 [==============================] - 1s 78us/sample - loss: 0.1545 - accuracy: 0.9851\n",
      "Epoch 28/50\n",
      "7332/7332 [==============================] - 1s 93us/sample - loss: 0.1549 - accuracy: 0.9840\n",
      "Epoch 29/50\n",
      "7332/7332 [==============================] - 1s 83us/sample - loss: 0.1544 - accuracy: 0.9835\n",
      "Epoch 30/50\n",
      "7332/7332 [==============================] - 1s 91us/sample - loss: 0.1551 - accuracy: 0.9849\n",
      "Epoch 31/50\n",
      "7332/7332 [==============================] - 1s 92us/sample - loss: 0.1539 - accuracy: 0.9851\n",
      "Epoch 32/50\n",
      "7332/7332 [==============================] - 1s 100us/sample - loss: 0.1548 - accuracy: 0.9846\n",
      "Epoch 33/50\n",
      "7332/7332 [==============================] - 1s 91us/sample - loss: 0.1540 - accuracy: 0.9839\n",
      "Epoch 34/50\n",
      "7332/7332 [==============================] - 1s 98us/sample - loss: 0.1550 - accuracy: 0.9840\n",
      "Epoch 35/50\n",
      "7332/7332 [==============================] - 1s 92us/sample - loss: 0.1545 - accuracy: 0.9842\n",
      "Epoch 36/50\n",
      "7332/7332 [==============================] - 1s 92us/sample - loss: 0.1544 - accuracy: 0.9847\n",
      "Epoch 37/50\n",
      "7332/7332 [==============================] - 1s 90us/sample - loss: 0.1532 - accuracy: 0.9847\n",
      "Epoch 38/50\n",
      "7332/7332 [==============================] - 1s 93us/sample - loss: 0.1543 - accuracy: 0.9854\n",
      "Epoch 39/50\n",
      "7332/7332 [==============================] - 1s 87us/sample - loss: 0.1545 - accuracy: 0.9850\n",
      "Epoch 40/50\n",
      "7332/7332 [==============================] - 1s 91us/sample - loss: 0.1549 - accuracy: 0.9847\n",
      "Epoch 41/50\n",
      "7332/7332 [==============================] - 1s 90us/sample - loss: 0.1540 - accuracy: 0.9843\n",
      "Epoch 42/50\n",
      "7332/7332 [==============================] - 1s 91us/sample - loss: 0.1547 - accuracy: 0.9831\n",
      "Epoch 43/50\n",
      "7332/7332 [==============================] - 1s 90us/sample - loss: 0.1541 - accuracy: 0.9846\n",
      "Epoch 44/50\n",
      "7332/7332 [==============================] - 1s 91us/sample - loss: 0.1547 - accuracy: 0.9850\n",
      "Epoch 45/50\n",
      "7332/7332 [==============================] - 1s 87us/sample - loss: 0.1546 - accuracy: 0.9846\n",
      "Epoch 46/50\n",
      "7332/7332 [==============================] - 1s 86us/sample - loss: 0.1545 - accuracy: 0.9850\n",
      "Epoch 47/50\n",
      "7332/7332 [==============================] - 1s 88us/sample - loss: 0.1546 - accuracy: 0.9849\n",
      "Epoch 48/50\n",
      "7332/7332 [==============================] - 1s 80us/sample - loss: 0.1538 - accuracy: 0.9849\n",
      "Epoch 49/50\n",
      "7332/7332 [==============================] - 1s 83us/sample - loss: 0.1548 - accuracy: 0.9849\n",
      "Epoch 50/50\n",
      "7332/7332 [==============================] - 1s 97us/sample - loss: 0.1544 - accuracy: 0.9850\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1037\n",
      "           1       0.79      1.00      0.89        58\n",
      "           2       0.83      0.92      0.87        37\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1132\n",
      "   macro avg       0.87      0.97      0.92      1132\n",
      "weighted avg       0.98      0.98      0.98      1132\n",
      "\n",
      "0.9594594594594594\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras_multiclass(X_train, y_train, X_test, n_iter=50, learning_rate=2)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred, average='macro', labels=[1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer modelling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_keras_multiclass(X_train, y_train, X_test, n_iter=100, learning_rate=0.05, inner_units=64):\n",
    "    X_train, y_train = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
    "    y_train = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=inner_units, input_dim=X_train.shape[1], activation='tanh'))\n",
    "    model.add(Dense(units=3, input_dim=inner_units, activation='softmax'))\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.SGD(lr=learning_rate),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(X_train, y_train, epochs=n_iter)\n",
    "    return np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7332/7332 [==============================] - 1s 114us/sample - loss: 0.5946 - accuracy: 0.8022\n",
      "Epoch 2/10\n",
      "7332/7332 [==============================] - 1s 94us/sample - loss: 0.3434 - accuracy: 0.9554\n",
      "Epoch 3/10\n",
      "7332/7332 [==============================] - 1s 93us/sample - loss: 0.2474 - accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "7332/7332 [==============================] - 1s 99us/sample - loss: 0.1981 - accuracy: 0.9772\n",
      "Epoch 5/10\n",
      "7332/7332 [==============================] - 1s 93us/sample - loss: 0.1712 - accuracy: 0.9774\n",
      "Epoch 6/10\n",
      "7332/7332 [==============================] - 1s 93us/sample - loss: 0.1556 - accuracy: 0.9794\n",
      "Epoch 7/10\n",
      "7332/7332 [==============================] - 1s 88us/sample - loss: 0.1453 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "7332/7332 [==============================] - 1s 89us/sample - loss: 0.1381 - accuracy: 0.9821\n",
      "Epoch 9/10\n",
      "7332/7332 [==============================] - 1s 89us/sample - loss: 0.1326 - accuracy: 0.9819\n",
      "Epoch 10/10\n",
      "7332/7332 [==============================] - 1s 90us/sample - loss: 0.1289 - accuracy: 0.9820\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1037\n",
      "           1       0.77      1.00      0.87        58\n",
      "           2       0.88      0.97      0.92        37\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1132\n",
      "   macro avg       0.88      0.98      0.93      1132\n",
      "weighted avg       0.98      0.98      0.98      1132\n",
      "\n",
      "0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras_multiclass(X_train, y_train, X_test, n_iter=10, learning_rate=0.05, inner_units=128)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred, average='macro', labels=[1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston houses dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "df = pd.DataFrame(dataset['data'], columns=dataset['feature_names'])\n",
    "df['target'] = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(df.columns) - set('target'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['target'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((354, 14), (152, 14))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFLineReg(TFLogReg):\n",
    "    def _predict(self, X):\n",
    "        return tf.matmul(X, self.W) + self.b\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._predict(X).numpy().T[0]\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_ = self._predict(X)\n",
    "            loss = tf.reduce_mean((y - y_) ** 2)\n",
    "            W_grad, b_grad = tape.gradient(loss, [self.W, self.b])\n",
    "        return W_grad, b_grad\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.W = tf.Variable(tf.zeros([X_train.shape[1], 1], dtype=X.dtype))\n",
    "        self.b = tf.Variable(tf.zeros([1], dtype=X.dtype))\n",
    "        \n",
    "        for i in range(self.n_iter):\n",
    "            W_grad, b_grad = self.train_step(X, y.values.reshape(-1, 1))\n",
    "\n",
    "            self.W.assign_sub(self.lr * W_grad)\n",
    "            self.b.assign_sub(self.lr * b_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.069037362917812e-13"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFLineReg(n_iter=1000, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.600000</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>29.800000</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>17.799999</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>24.600000</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.700000</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>20.200000</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>23.200000</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>13.800001</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21.200000</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>23.200000</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  target\n",
       "24   15.600000    15.6\n",
       "473  29.800000    29.8\n",
       "148  17.799999    17.8\n",
       "325  24.600000    24.6\n",
       "2    34.700000    34.7\n",
       "463  20.200000    20.2\n",
       "176  23.200000    23.2\n",
       "393  13.800001    13.8\n",
       "44   21.200000    21.2\n",
       "472  23.200000    23.2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'score': y_pred, 'target': y_test})[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear_regression_keras(X_train, y_train, X_test, n_iter=100, learning_rate=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, input_dim=X_train.shape[1], activation='linear'))\n",
    "    model.compile(loss=keras.losses.mean_squared_error, optimizer=keras.optimizers.SGD(lr=learning_rate), metrics=[keras.metrics.mean_squared_error])\n",
    "    model.fit(X_train, y_train, epochs=n_iter)\n",
    "    return model.predict(X_test).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 457us/step - loss: 153.5555 - mean_squared_error: 153.5555\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 4.1904 - mean_squared_error: 4.1904\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 58us/step - loss: 1.5587 - mean_squared_error: 1.5587\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.8104 - mean_squared_error: 0.8104\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.2789 - mean_squared_error: 0.2789\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 0.1506 - mean_squared_error: 0.1506\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 55us/step - loss: 0.0933 - mean_squared_error: 0.0933\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 0.0500 - mean_squared_error: 0.0500\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 0.0868 - mean_squared_error: 0.0868\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 0.0163 - mean_squared_error: 0.0163\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 55us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0011 - mean_squared_error: 0.0011   \n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 7.4419e-04 - mean_squared_error: 7.4419e-04\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 55us/step - loss: 2.8441e-04 - mean_squared_error: 2.8441e-04\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 52us/step - loss: 2.1014e-04 - mean_squared_error: 2.1014e-04\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 1.4552e-04 - mean_squared_error: 1.4552e-04\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 1.1321e-04 - mean_squared_error: 1.1321e-04\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 8.4081e-05 - mean_squared_error: 8.4081e-05\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 7.8531e-05 - mean_squared_error: 7.8531e-05\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 5.2846e-05 - mean_squared_error: 5.2846e-05\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 4.5117e-05 - mean_squared_error: 4.5117e-05\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 2.9105e-05 - mean_squared_error: 2.9105e-05\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 52us/step - loss: 2.6520e-05 - mean_squared_error: 2.6520e-05\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 55us/step - loss: 1.7239e-05 - mean_squared_error: 1.7239e-05\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 1.2592e-05 - mean_squared_error: 1.2592e-05\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 9.8832e-06 - mean_squared_error: 9.8832e-06\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 7.7295e-06 - mean_squared_error: 7.7295e-06\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 58us/step - loss: 5.6559e-06 - mean_squared_error: 5.6559e-06\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 60us/step - loss: 3.8999e-06 - mean_squared_error: 3.8999e-06\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 3.6266e-06 - mean_squared_error: 3.6266e-06\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 2.2679e-06 - mean_squared_error: 2.2679e-06\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 1.8481e-06 - mean_squared_error: 1.8481e-06\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 1.3951e-06 - mean_squared_error: 1.3951e-06\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 1.0046e-06 - mean_squared_error: 1.0046e-06\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 52us/step - loss: 8.7468e-07 - mean_squared_error: 8.7468e-07\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 6.3942e-07 - mean_squared_error: 6.3942e-07\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 4.7013e-07 - mean_squared_error: 4.7013e-07\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 3.6887e-07 - mean_squared_error: 3.6887e-07\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 2.9864e-07 - mean_squared_error: 2.9864e-07\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 2.0514e-07 - mean_squared_error: 2.0514e-07\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 1.6142e-07 - mean_squared_error: 1.6142e-07\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 1.2786e-07 - mean_squared_error: 1.2786e-07\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 1.0208e-07 - mean_squared_error: 1.0208e-07\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 6.2107e-08 - mean_squared_error: 6.2107e-08\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 5.3811e-08 - mean_squared_error: 5.3811e-08\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 4.5389e-08 - mean_squared_error: 4.5389e-08\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 3.3963e-08 - mean_squared_error: 3.3963e-08\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 2.6256e-08 - mean_squared_error: 2.6256e-08\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 1.3790e-08 - mean_squared_error: 1.3790e-08\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 1.0285e-08 - mean_squared_error: 1.0285e-08\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 8.8239e-09 - mean_squared_error: 8.8239e-09\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 45us/step - loss: 5.7442e-09 - mean_squared_error: 5.7442e-09\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 4.4885e-09 - mean_squared_error: 4.4885e-09\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 4.4637e-09 - mean_squared_error: 4.4637e-09\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 45us/step - loss: 2.3672e-09 - mean_squared_error: 2.3672e-09\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 2.0880e-09 - mean_squared_error: 2.0880e-09\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 2.7007e-09 - mean_squared_error: 2.7007e-09\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 9.1042e-10 - mean_squared_error: 9.1042e-10\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 47us/step - loss: 6.7292e-10 - mean_squared_error: 6.7292e-10\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 4.8522e-10 - mean_squared_error: 4.8522e-10\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 3.8312e-10 - mean_squared_error: 3.8312e-10\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 6.3811e-10 - mean_squared_error: 6.3811e-10\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 2.0781e-10 - mean_squared_error: 2.0781e-10\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 1.5194e-10 - mean_squared_error: 1.5194e-10\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 1.6593e-10 - mean_squared_error: 1.6593e-10\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 7.2617e-11 - mean_squared_error: 7.2617e-11\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 5.5036e-11 - mean_squared_error: 5.5036e-11\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 47us/step - loss: 6.1474e-11 - mean_squared_error: 6.1474e-11\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 2.9647e-11 - mean_squared_error: 2.9647e-11\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 43us/step - loss: 2.1716e-11 - mean_squared_error: 2.1716e-11\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 1.4959e-11 - mean_squared_error: 1.4959e-11\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 1.2819e-11 - mean_squared_error: 1.2819e-11\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 50us/step - loss: 1.0507e-11 - mean_squared_error: 1.0507e-11\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 7.3209e-12 - mean_squared_error: 7.3209e-12\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 6.2187e-12 - mean_squared_error: 6.2187e-12\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 5.4249e-12 - mean_squared_error: 5.4249e-12\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 4.3021e-12 - mean_squared_error: 4.3021e-12\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 45us/step - loss: 3.7395e-12 - mean_squared_error: 3.7395e-12\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 3.0329e-12 - mean_squared_error: 3.0329e-12\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 2.8068e-12 - mean_squared_error: 2.8068e-12\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 2.5808e-12 - mean_squared_error: 2.5808e-12\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 45us/step - loss: 3.4748e-12 - mean_squared_error: 3.4748e-12\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 49us/step - loss: 2.2134e-12 - mean_squared_error: 2.2134e-12\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 69us/step - loss: 2.1440e-12 - mean_squared_error: 2.1440e-12\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 60us/step - loss: 2.6090e-12 - mean_squared_error: 2.6090e-12\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 47us/step - loss: 2.2365e-12 - mean_squared_error: 2.2365e-12\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 45us/step - loss: 2.0823e-12 - mean_squared_error: 2.0823e-12\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 2.0721e-12 - mean_squared_error: 2.0721e-12\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 46us/step - loss: 1.5916e-12 - mean_squared_error: 1.5916e-12\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 1.8177e-12 - mean_squared_error: 1.8177e-12\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 53us/step - loss: 1.6892e-12 - mean_squared_error: 1.6892e-12\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 2.1414e-12 - mean_squared_error: 2.1414e-12\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 55us/step - loss: 8.8252e-13 - mean_squared_error: 8.8252e-13\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 52us/step - loss: 5.4338e-13 - mean_squared_error: 5.4338e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7887634547854056e-13"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_linear_regression_keras(X_train, y_train, X_test, n_iter=100)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>25.100000</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>23.300001</td>\n",
       "      <td>23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>19.900002</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>17.799999</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>35.400002</td>\n",
       "      <td>35.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>24.799999</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>11.800000</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  target\n",
       "236  25.100000    25.1\n",
       "216  23.300001    23.3\n",
       "91   22.000000    22.0\n",
       "470  19.900002    19.9\n",
       "356  17.799999    17.8\n",
       "281  35.400002    35.4\n",
       "405   5.000000     5.0\n",
       "300  24.799999    24.8\n",
       "445  11.800000    11.8\n",
       "416   7.500000     7.5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'score': y_pred, 'target': y_test})[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
