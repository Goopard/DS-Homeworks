{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, recall_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('titanic.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211,3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0,9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151,5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0     1.0       1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1     1.0       1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2     1.0       0.0                     Allison, Miss. Helen Loraine  female   \n",
       "3     1.0       0.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4     1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "      age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0      29    0.0    0.0   24160  211,3375       B5        S    2    NaN   \n",
       "1  0,9167    1.0    2.0  113781  151,5500  C22 C26        S   11    NaN   \n",
       "2       2    1.0    2.0  113781  151,5500  C22 C26        S  NaN    NaN   \n",
       "3      30    1.0    2.0  113781  151,5500  C22 C26        S  NaN  135.0   \n",
       "4      25    1.0    2.0  113781  151,5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['sex'] = pdf['sex'].map({'female': 1.0, 'male': 0.0})\n",
    "pdf['embarked'] = pdf['embarked'].map({'C': 0.0, 'Q': 1.0, 'S': 2.0})\n",
    "pdf['age'] = pdf['age'].apply(lambda val: str(val).replace(',', '.')).astype(float)\n",
    "pdf['fare'] = pdf['fare'].apply(lambda val: str(val).replace(',', '.')).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          1\n",
       "survived        1\n",
       "name            1\n",
       "sex             1\n",
       "age           264\n",
       "sibsp           1\n",
       "parch           1\n",
       "ticket          1\n",
       "fare            2\n",
       "cabin        1015\n",
       "embarked        3\n",
       "boat          824\n",
       "body         1189\n",
       "home.dest     565\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdf.dropna(subset=['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff914eab080>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf['age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff914649630>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf['fare'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing features analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass\n",
       "1.0    0.619195\n",
       "2.0    0.429603\n",
       "3.0    0.255289\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['pclass'])['survived'].sum() / pdf.groupby(['pclass']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "female    0.727468\n",
       "male      0.190985\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sex'])['survived'].sum() / pdf.groupby(['sex']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex     pclass\n",
       "female  1.0       0.965278\n",
       "        2.0       0.886792\n",
       "        3.0       0.490741\n",
       "male    1.0       0.340782\n",
       "        2.0       0.146199\n",
       "        3.0       0.152130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sex', 'pclass'])['survived'].sum() / pdf.groupby(['sex', 'pclass']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked\n",
       "C    0.555556\n",
       "Q    0.357724\n",
       "S    0.332604\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['embarked'])['survived'].sum() / pdf.groupby(['embarked']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parch\n",
       "0.0    0.335329\n",
       "1.0    0.588235\n",
       "2.0    0.504425\n",
       "3.0    0.625000\n",
       "4.0    0.166667\n",
       "5.0    0.166667\n",
       "6.0    0.000000\n",
       "9.0    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['parch'])['survived'].sum() / pdf.groupby(['parch']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boated\n",
       "0.0    0.027947\n",
       "1.0    0.981481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['boated'] = (~pdf['boat'].isna()).astype(float)\n",
    "pdf.groupby(['boated'])['survived'].sum() / pdf.groupby(['boated']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex     pclass  boated\n",
       "female  1.0     0.0       0.166667\n",
       "                1.0       1.000000\n",
       "        2.0     0.0       0.400000\n",
       "                1.0       1.000000\n",
       "        3.0     0.0       0.099174\n",
       "                1.0       0.989474\n",
       "male    1.0     0.0       0.000000\n",
       "                1.0       0.968254\n",
       "        2.0     0.0       0.000000\n",
       "                1.0       0.961538\n",
       "        3.0     0.0       0.004819\n",
       "                1.0       0.935897\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sex', 'pclass', 'boated'])['survived'].sum() / pdf.groupby(['sex', 'pclass', 'boated']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sibsp\n",
       "0.0    0.346801\n",
       "1.0    0.510972\n",
       "2.0    0.452381\n",
       "3.0    0.300000\n",
       "4.0    0.136364\n",
       "5.0    0.000000\n",
       "8.0    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.groupby(['sibsp'])['survived'].sum() / pdf.groupby(['sibsp']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['boated', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked', 'fare']\n",
    "pdf_clear = pdf[features + ['survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(pdf_clear[features], pdf_clear['survived'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=features)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=features)\n",
    "y_train = pd.Series(y_train.values)\n",
    "y_test = pd.Series(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, y, batch_size=10):\n",
    "    indices = np.random.choice(X.index, batch_size)\n",
    "    return X.loc[indices], y.loc[indices]\n",
    "\n",
    "\n",
    "def predict_logistic_regression_tf(X_train, y_train, X_test, n_iter=100, learning_rate=0.05, batch_size=50):\n",
    "    x = tf.placeholder(tf.float32, [None, X_train.shape[1]])\n",
    "    y = tf.placeholder(tf.float32, [None, 1])\n",
    "    W = tf.Variable(tf.zeros([X_train.shape[1], 1]))\n",
    "    b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "    logit = tf.matmul(x, W) + b\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=y))\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    prediction = tf.nn.sigmoid(logit)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        batch_xs, batch_ys = get_batch(X_train, y_train, batch_size=batch_size)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y: np.array([batch_ys.values]).T})\n",
    "\n",
    "    return sess.run(prediction, feed_dict={x: X_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try two different approaches of NaN-dealing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97       416\n",
      "         1.0       0.95      0.97      0.96       239\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       655\n",
      "   macro avg       0.96      0.97      0.97       655\n",
      "weighted avg       0.97      0.97      0.97       655\n",
      "\n",
      "ROC-AUC score: 0.9878952767943353\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_tf(X_train.fillna(0.0), y_train, X_test.fillna(0.0), n_iter=10, learning_rate=0.1, batch_size=50)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_mean(df):\n",
    "    return df.fillna({col: df[col].mean() for col in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97       416\n",
      "         1.0       0.95      0.96      0.95       239\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       655\n",
      "   macro avg       0.96      0.97      0.96       655\n",
      "weighted avg       0.97      0.97      0.97       655\n",
      "\n",
      "ROC-AUC score: 0.9886093900869005\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_tf(fillna_mean(X_train), y_train, fillna_mean(X_test), n_iter=10, learning_rate=0.1, batch_size=50)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_keras(X_train, y_train, X_test, n_iter=100, learning_rate=0.05, batch_size=50):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=n_iter)\n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.3966 - acc: 0.8807\n",
      "Epoch 2/10\n",
      "654/654 [==============================] - 0s 52us/step - loss: 0.2550 - acc: 0.9602\n",
      "Epoch 3/10\n",
      "654/654 [==============================] - 0s 58us/step - loss: 0.1968 - acc: 0.9664\n",
      "Epoch 4/10\n",
      "654/654 [==============================] - 0s 52us/step - loss: 0.1667 - acc: 0.9679\n",
      "Epoch 5/10\n",
      "654/654 [==============================] - 0s 53us/step - loss: 0.1486 - acc: 0.9709\n",
      "Epoch 6/10\n",
      "654/654 [==============================] - 0s 52us/step - loss: 0.1362 - acc: 0.9709\n",
      "Epoch 7/10\n",
      "654/654 [==============================] - 0s 62us/step - loss: 0.1277 - acc: 0.9709\n",
      "Epoch 8/10\n",
      "654/654 [==============================] - 0s 55us/step - loss: 0.1212 - acc: 0.9709\n",
      "Epoch 9/10\n",
      "654/654 [==============================] - 0s 54us/step - loss: 0.1162 - acc: 0.9709\n",
      "Epoch 10/10\n",
      "654/654 [==============================] - 0s 54us/step - loss: 0.1122 - acc: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98       416\n",
      "         1.0       0.97      0.97      0.97       239\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       655\n",
      "   macro avg       0.98      0.98      0.98       655\n",
      "weighted avg       0.98      0.98      0.98       655\n",
      "\n",
      "ROC-AUC score: 0.9915563646604443\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras(X_train.fillna(0.0), y_train, X_test.fillna(0.0), n_iter=10, learning_rate=0.1, batch_size=50)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling NaNs with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.6665 - acc: 0.6239\n",
      "Epoch 2/10\n",
      "654/654 [==============================] - 0s 55us/step - loss: 0.3424 - acc: 0.8884\n",
      "Epoch 3/10\n",
      "654/654 [==============================] - 0s 50us/step - loss: 0.2416 - acc: 0.9602\n",
      "Epoch 4/10\n",
      "654/654 [==============================] - 0s 50us/step - loss: 0.1937 - acc: 0.9694\n",
      "Epoch 5/10\n",
      "654/654 [==============================] - 0s 52us/step - loss: 0.1659 - acc: 0.9709\n",
      "Epoch 6/10\n",
      "654/654 [==============================] - 0s 56us/step - loss: 0.1482 - acc: 0.9709\n",
      "Epoch 7/10\n",
      "654/654 [==============================] - 0s 55us/step - loss: 0.1362 - acc: 0.9709\n",
      "Epoch 8/10\n",
      "654/654 [==============================] - 0s 53us/step - loss: 0.1275 - acc: 0.9709\n",
      "Epoch 9/10\n",
      "654/654 [==============================] - 0s 57us/step - loss: 0.1210 - acc: 0.9709\n",
      "Epoch 10/10\n",
      "654/654 [==============================] - 0s 52us/step - loss: 0.1159 - acc: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98       416\n",
      "         1.0       0.97      0.97      0.97       239\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       655\n",
      "   macro avg       0.98      0.98      0.98       655\n",
      "weighted avg       0.98      0.98      0.98       655\n",
      "\n",
      "ROC-AUC score: 0.9919888558094625\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras(fillna_mean(X_train), y_train, fillna_mean(X_test), n_iter=10, learning_rate=0.1, batch_size=50)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred > 0.5))\n",
    "print('ROC-AUC score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras model is a bit better, but still the results are almost the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thyroid Disease DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already done a full EDA of this dataset in HW3, so we will just be using preprocessed train and test sets from that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('thyroid_train.csv')\n",
    "test = pd.read_csv('thyroid_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSH</th>\n",
       "      <th>TT4</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>T4U</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.178313</td>\n",
       "      <td>-0.984492</td>\n",
       "      <td>0</td>\n",
       "      <td>1.176381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.165593</td>\n",
       "      <td>-0.070426</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.662252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.093509</td>\n",
       "      <td>-0.896034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.106229</td>\n",
       "      <td>0.047518</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.554097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166441</td>\n",
       "      <td>1.226959</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TSH       TT4  on_thyroxine       T4U  Class\n",
       "0 -0.178313 -0.984492             0  1.176381      0\n",
       "1 -0.165593 -0.070426             0 -0.662252      0\n",
       "2 -0.093509 -0.896034             0  0.257065      0\n",
       "3 -0.106229  0.047518             0 -0.554097      0\n",
       "4 -0.166441  1.226959             0  0.202987      0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2444\n",
       "1     136\n",
       "2      60\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1037\n",
       "1      58\n",
       "2      37\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSH             0\n",
       "TT4             0\n",
       "on_thyroxine    0\n",
       "T4U             0\n",
       "Class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSH             0\n",
       "TT4             0\n",
       "on_thyroxine    0\n",
       "Class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TSH', 'TT4', 'on_thyroxine', 'T4U']\n",
    "X_train = train[cols]\n",
    "X_test = test[cols]\n",
    "y_train = train['Class']\n",
    "y_test = test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_tf_multiclass(X_train, y_train, X_test, n_iter=100, learning_rate=0.05):\n",
    "    x = tf.placeholder(tf.float32, [None, X_train.shape[1]])\n",
    "    y = tf.placeholder(tf.float32, [None, 3])\n",
    "    W = tf.Variable(tf.zeros([X_train.shape[1], 3]))\n",
    "    b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "    logit = tf.matmul(x, W) + b\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y))\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    prediction = tf.argmax(tf.nn.softmax(logit), 1)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    X_train, y_train = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
    "    y_train = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "    for i in range(n_iter):\n",
    "        sess.run(train_step, feed_dict={x: X_train, y: y_train})\n",
    "\n",
    "    return sess.run(prediction, feed_dict={x: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1037\n",
      "           1       0.82      1.00      0.90        58\n",
      "           2       0.82      0.97      0.89        37\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1132\n",
      "   macro avg       0.88      0.98      0.93      1132\n",
      "weighted avg       0.98      0.98      0.98      1132\n",
      "\n",
      "0.9864864864864865\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_tf_multiclass(X_train, y_train, X_test, n_iter=500, learning_rate=4)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred, average='macro', labels=[1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually we even got a bit better result than in the original HW3 (0.969)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression_keras_multiclass(X_train, y_train, X_test, n_iter=100, learning_rate=0.05):\n",
    "    X_train, y_train = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
    "    y_train = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=3, input_dim=X_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=n_iter)\n",
    "    return np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7332/7332 [==============================] - 2s 226us/step - loss: 0.3080 - acc: 0.9303\n",
      "Epoch 2/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.1653 - acc: 0.9780\n",
      "Epoch 3/50\n",
      "7332/7332 [==============================] - 0s 49us/step - loss: 0.1405 - acc: 0.9793\n",
      "Epoch 4/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.1266 - acc: 0.9816\n",
      "Epoch 5/50\n",
      "7332/7332 [==============================] - 0s 45us/step - loss: 0.1183 - acc: 0.9824\n",
      "Epoch 6/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.1135 - acc: 0.9821\n",
      "Epoch 7/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.1095 - acc: 0.9840\n",
      "Epoch 8/50\n",
      "7332/7332 [==============================] - 0s 45us/step - loss: 0.1060 - acc: 0.9834\n",
      "Epoch 9/50\n",
      "7332/7332 [==============================] - 0s 49us/step - loss: 0.1035 - acc: 0.9853\n",
      "Epoch 10/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.1011 - acc: 0.9853\n",
      "Epoch 11/50\n",
      "7332/7332 [==============================] - 0s 50us/step - loss: 0.0996 - acc: 0.9845\n",
      "Epoch 12/50\n",
      "7332/7332 [==============================] - 0s 55us/step - loss: 0.0975 - acc: 0.9858\n",
      "Epoch 13/50\n",
      "7332/7332 [==============================] - 0s 52us/step - loss: 0.0966 - acc: 0.9857\n",
      "Epoch 14/50\n",
      "7332/7332 [==============================] - 0s 51us/step - loss: 0.0954 - acc: 0.9851\n",
      "Epoch 15/50\n",
      "7332/7332 [==============================] - 0s 52us/step - loss: 0.0951 - acc: 0.9855\n",
      "Epoch 16/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0938 - acc: 0.9862\n",
      "Epoch 17/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0930 - acc: 0.9861\n",
      "Epoch 18/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0928 - acc: 0.9858\n",
      "Epoch 19/50\n",
      "7332/7332 [==============================] - 0s 45us/step - loss: 0.0918 - acc: 0.9866\n",
      "Epoch 20/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0909 - acc: 0.9866\n",
      "Epoch 21/50\n",
      "7332/7332 [==============================] - 0s 49us/step - loss: 0.0901 - acc: 0.9869\n",
      "Epoch 22/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0895 - acc: 0.9862\n",
      "Epoch 23/50\n",
      "7332/7332 [==============================] - 0s 49us/step - loss: 0.0891 - acc: 0.9870\n",
      "Epoch 24/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0885 - acc: 0.9866\n",
      "Epoch 25/50\n",
      "7332/7332 [==============================] - 0s 45us/step - loss: 0.0880 - acc: 0.9875\n",
      "Epoch 26/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0872 - acc: 0.9879\n",
      "Epoch 27/50\n",
      "7332/7332 [==============================] - 0s 49us/step - loss: 0.0874 - acc: 0.9869\n",
      "Epoch 28/50\n",
      "7332/7332 [==============================] - 0s 45us/step - loss: 0.0867 - acc: 0.9876\n",
      "Epoch 29/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0864 - acc: 0.9869\n",
      "Epoch 30/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0860 - acc: 0.9880\n",
      "Epoch 31/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0851 - acc: 0.9877\n",
      "Epoch 32/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0850 - acc: 0.9880\n",
      "Epoch 33/50\n",
      "7332/7332 [==============================] - 0s 51us/step - loss: 0.0849 - acc: 0.9884\n",
      "Epoch 34/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0848 - acc: 0.9885\n",
      "Epoch 35/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0841 - acc: 0.9877\n",
      "Epoch 36/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0842 - acc: 0.9880\n",
      "Epoch 37/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0835 - acc: 0.9877\n",
      "Epoch 38/50\n",
      "7332/7332 [==============================] - 0s 49us/step - loss: 0.0839 - acc: 0.9880\n",
      "Epoch 39/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0829 - acc: 0.9890\n",
      "Epoch 40/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0828 - acc: 0.9881\n",
      "Epoch 41/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0828 - acc: 0.9888\n",
      "Epoch 42/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0823 - acc: 0.9881\n",
      "Epoch 43/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0823 - acc: 0.9884\n",
      "Epoch 44/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0820 - acc: 0.9883\n",
      "Epoch 45/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0815 - acc: 0.9892\n",
      "Epoch 46/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0812 - acc: 0.9887\n",
      "Epoch 47/50\n",
      "7332/7332 [==============================] - 0s 46us/step - loss: 0.0810 - acc: 0.9892\n",
      "Epoch 48/50\n",
      "7332/7332 [==============================] - 0s 47us/step - loss: 0.0809 - acc: 0.9890\n",
      "Epoch 49/50\n",
      "7332/7332 [==============================] - 0s 48us/step - loss: 0.0848 - acc: 0.9877\n",
      "Epoch 50/50\n",
      "7332/7332 [==============================] - 0s 52us/step - loss: 0.0807 - acc: 0.9890: 0s - loss: 0.0813 - acc: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1037\n",
      "           1       0.81      1.00      0.89        58\n",
      "           2       0.83      0.92      0.87        37\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1132\n",
      "   macro avg       0.88      0.97      0.92      1132\n",
      "weighted avg       0.98      0.98      0.98      1132\n",
      "\n",
      "0.9594594594594594\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logistic_regression_keras_multiclass(X_train, y_train, X_test, n_iter=50, learning_rate=2)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred, average='macro', labels=[1, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
