{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "from functools import reduce, partial\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from pyspark.sql import SparkSession\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.metrics import roc_auc_score, classification_report, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vagrant/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(dir_path, label):\n",
    "    raw = []\n",
    "    paths = os.listdir(dir_path)\n",
    "    num_paths = len(paths)\n",
    "    for i in tqdm(range(num_paths)):\n",
    "        with open(os.path.join(dir_path, paths[i]), 'r') as file:\n",
    "            raw.append(file.read())\n",
    "    \n",
    "    return pd.DataFrame(list(zip(raw, [label] * len(raw))), columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:37<00:00, 79.48it/s]\n",
      "100%|██████████| 12500/12500 [02:26<00:00, 85.54it/s]\n",
      "100%|██████████| 12500/12500 [01:34<00:00, 132.58it/s]\n",
      "100%|██████████| 12500/12500 [01:34<00:00, 131.71it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_train_df = read_files('./aclImdb/train/pos', 1)\n",
    "neg_train_df = read_files('./aclImdb/train/neg', 0)\n",
    "\n",
    "pos_test_df = read_files('./aclImdb/test/pos', 1)\n",
    "neg_test_df = read_files('./aclImdb/test/neg', 0)\n",
    "\n",
    "train_df = pd.concat([pos_train_df, neg_train_df])\n",
    "test_df = pd.concat([pos_test_df, neg_test_df])\n",
    "\n",
    "train_df.index = pd.RangeIndex(25000)\n",
    "test_df.index = pd.RangeIndex(25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to get any useful information from the texts themselves, without any deep analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347.16024 982.0\n"
     ]
    }
   ],
   "source": [
    "pos_lengths = pos_train_df['text'].apply(lambda text: len(text))\n",
    "plt.hist(pos_lengths, bins=30)\n",
    "plt.show()\n",
    "print(pos_lengths.mean(), pos_lengths.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302.97904 976.5\n"
     ]
    }
   ],
   "source": [
    "neg_lengths = neg_train_df['text'].apply(lambda text: len(text))\n",
    "plt.hist(neg_lengths, bins=30)\n",
    "plt.show()\n",
    "print(neg_lengths.mean(), neg_lengths.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative reviewes tend to be just a bit shorter, but this is defintely not significant and won't help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236.69568, 174.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_words = pos_train_df['text'].apply(lambda text: len(text.split(' ')))\n",
    "plt.hist(pos_words, bins=30)\n",
    "pos_words.mean(), pos_words.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230.85776, 174.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_words = neg_train_df['text'].apply(lambda text: len(text.split(' ')))\n",
    "plt.hist(neg_words, bins=30)\n",
    "neg_words.mean(), neg_words.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even closer and more useless results in terms of length of review in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.660490237310027, 4.650445970479122)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_word_lengths = pos_train_df['text'].apply(lambda text: sum([len(word) for word in text.split(' ')]) / len(text.split(' ')))\n",
    "plt.hist(pos_word_lengths, bins=30)\n",
    "pos_word_lengths.mean(), pos_word_lengths.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.627433057309819, 4.612451550387597)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_word_lengths = neg_train_df['text'].apply(lambda text: sum([len(word) for word in text.split(' ')]) / len(text.split(' ')))\n",
    "plt.hist(neg_word_lengths, bins=30)\n",
    "neg_word_lengths.mean(), neg_word_lengths.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average length of word is pretty much the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.master('local[*]').config('spark.driver.memory', '5G').config('spark.executor.memory', '5G').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(series, stemmer, lemmatizer=False):\n",
    "    tokenizer = RegexpTokenizer(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    rdd = ss.sparkContext.parallelize(series.values)\n",
    "    tokenized_rdd = rdd.map(lambda text: tokenizer.tokenize(text))\n",
    "    if not lemmatizer:\n",
    "        stemed_rdd = tokenized_rdd.map(lambda words: [stemmer.stem(word) for word in words])\n",
    "    else:\n",
    "        stemed_rdd = tokenized_rdd.map(lambda words: [stemmer.lemmatize(word) for word in words])\n",
    "    text_rdd = stemed_rdd.map(lambda words: '|'.join(words))\n",
    "    return pd.Series(text_rdd.collect())\n",
    "\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    try:\n",
    "        predictions = model.predict_proba(X_test)[:, 1]\n",
    "    except AttributeError:\n",
    "        predictions = model.predict(X_test)\n",
    "    return classification_report(y_test, predictions > 0.5), roc_auc_score(y_test, predictions)\n",
    "\n",
    "def word_importances(bag_of_words, model, num=10):\n",
    "    feature_names = bag_of_words.get_feature_names()\n",
    "    importances = model.coef_[0]\n",
    "\n",
    "    word_importances = pd.DataFrame({'word': feature_names, 'importance': importances})\n",
    "    bad_words = word_importances.sort_values('importance').head(num)\n",
    "    good_words = word_importances.sort_values('importance', ascending=False).head(num)\n",
    "    return pd.DataFrame({\n",
    "        'bad_word': bad_words['word'].values,\n",
    "        'bad_importance': bad_words['importance'].values,\n",
    "        'good_word': good_words['word'].values,\n",
    "        'good_importance': good_words['importance'].values\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemed_train = tokenize_and_stem(train_df['text'], WordNetLemmatizer(), lemmatizer=True)\n",
    "stemed_test = tokenize_and_stem(test_df['text'], WordNetLemmatizer(), lemmatizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes + Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = CountVectorizer(max_features=10000, max_df=0.3, stop_words='english')\n",
    "bag_train = bag_of_words.fit_transform(train_df['text'])\n",
    "bag_test = bag_of_words.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85     12500\n",
      "           1       0.87      0.79      0.83     12500\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "0.9116382272\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB(alpha=100)\n",
    "report, roc_auc = evaluate_model(bag_train, train_df['label'], bag_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to use stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_stem = CountVectorizer(max_features=10000, max_df=0.3, stop_words='english')\n",
    "bag_stemed_train = bag_of_words_stem.fit_transform(stemed_train)\n",
    "bag_stemed_test = bag_of_words_stem.transform(stemed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84     12500\n",
      "           1       0.87      0.79      0.83     12500\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "0.9089294944\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB(alpha=100)\n",
    "report, roc_auc = evaluate_model(bag_stemed_train, train_df['label'], bag_stemed_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not really different from the ones we achieved without stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression + Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's try the logistic regression without any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     12500\n",
      "           1       0.85      0.84      0.84     12500\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "0.919399936\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "report, roc_auc = evaluate_model(bag_train, train_df['label'], bag_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use GridSearch to improve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_iter': [50, 100, 150, 200], 'solver': ['saga', 'sag', 'newton-cg', 'liblinear', 'lbfgs'], 'C': [0.5, 0.75, 1], 'penalty': ['l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(roc_auc_score), verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_iter': [50, 100, 150, 200],\n",
    "    'solver': ['saga', 'sag', 'newton-cg', 'liblinear', 'lbfgs'],\n",
    "    'C': [0.5, 0.75, 1],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), params, scoring=make_scorer(roc_auc_score))\n",
    "grid.fit(bag_train, train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.75, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87     12500\n",
      "           1       0.87      0.88      0.87     12500\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "0.944405312\n"
     ]
    }
   ],
   "source": [
    "report, roc_auc = evaluate_model(bag_train, train_df['label'], bag_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the word importnaces to see if the model is basing it's results on the same words as a real person would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_importance</th>\n",
       "      <th>bad_word</th>\n",
       "      <th>good_importance</th>\n",
       "      <th>good_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.274459</td>\n",
       "      <td>worst</td>\n",
       "      <td>0.840432</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.102335</td>\n",
       "      <td>waste</td>\n",
       "      <td>0.665097</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.969169</td>\n",
       "      <td>awful</td>\n",
       "      <td>0.654195</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.827151</td>\n",
       "      <td>boring</td>\n",
       "      <td>0.641881</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.722151</td>\n",
       "      <td>worse</td>\n",
       "      <td>0.604825</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.710821</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.561751</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.693563</td>\n",
       "      <td>dull</td>\n",
       "      <td>0.539155</td>\n",
       "      <td>superb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.676435</td>\n",
       "      <td>poor</td>\n",
       "      <td>0.526806</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.651050</td>\n",
       "      <td>horrible</td>\n",
       "      <td>0.508314</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.647481</td>\n",
       "      <td>disappointment</td>\n",
       "      <td>0.507958</td>\n",
       "      <td>brilliant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad_importance        bad_word  good_importance  good_word\n",
       "0       -1.274459           worst         0.840432  excellent\n",
       "1       -1.102335           waste         0.665097    perfect\n",
       "2       -0.969169           awful         0.654195  wonderful\n",
       "3       -0.827151          boring         0.641881   favorite\n",
       "4       -0.722151           worse         0.604825    amazing\n",
       "5       -0.710821          poorly         0.561751      loved\n",
       "6       -0.693563            dull         0.539155     superb\n",
       "7       -0.676435            poor         0.526806      today\n",
       "8       -0.651050        horrible         0.508314     highly\n",
       "9       -0.647481  disappointment         0.507958  brilliant"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances(bag_of_words, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's exactly what we expected it to be! \n",
    "\n",
    "Let's also try to add lemmitizing here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87     12500\n",
      "           1       0.87      0.88      0.87     12500\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "0.9426402304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "report, roc_auc = evaluate_model(bag_stemed_train, train_df['label'], bag_stemed_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not very helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier + Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     12500\n",
      "           1       0.87      0.88      0.88     12500\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "0.9437308863999999\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(loss='modified_huber', penalty='l1', max_iter=200, eta0=.00001, learning_rate='adaptive')\n",
    "report, roc_auc = evaluate_model(bag_train, train_df['label'], bag_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_importance</th>\n",
       "      <th>bad_word</th>\n",
       "      <th>good_importance</th>\n",
       "      <th>good_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.450256</td>\n",
       "      <td>worst</td>\n",
       "      <td>0.288845</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.426619</td>\n",
       "      <td>waste</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.358290</td>\n",
       "      <td>awful</td>\n",
       "      <td>0.242760</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.308053</td>\n",
       "      <td>disappointment</td>\n",
       "      <td>0.232948</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.305412</td>\n",
       "      <td>boring</td>\n",
       "      <td>0.221839</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.297672</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.220255</td>\n",
       "      <td>superb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.282433</td>\n",
       "      <td>dull</td>\n",
       "      <td>0.209129</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.270538</td>\n",
       "      <td>worse</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>enjoyable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.264528</td>\n",
       "      <td>disappointing</td>\n",
       "      <td>0.196812</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.252266</td>\n",
       "      <td>horrible</td>\n",
       "      <td>0.196013</td>\n",
       "      <td>perfectly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad_importance        bad_word  good_importance  good_word\n",
       "0       -0.450256           worst         0.288845  excellent\n",
       "1       -0.426619           waste         0.248054   favorite\n",
       "2       -0.358290           awful         0.242760    perfect\n",
       "3       -0.308053  disappointment         0.232948  wonderful\n",
       "4       -0.305412          boring         0.221839    amazing\n",
       "5       -0.297672          poorly         0.220255     superb\n",
       "6       -0.282433            dull         0.209129      loved\n",
       "7       -0.270538           worse         0.198171  enjoyable\n",
       "8       -0.264528   disappointing         0.196812      today\n",
       "9       -0.252266        horrible         0.196013  perfectly"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances(bag_of_words, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is the best we can get from Bag of words. Let's try some other methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000, stop_words='english', sublinear_tf=True, max_df=0.7)\n",
    "tfidf_train = tfidf.fit_transform(stemed_train)\n",
    "tfidf_test = tfidf.transform(stemed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     12500\n",
      "           1       0.87      0.80      0.83     12500\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "0.9194040319999999\n"
     ]
    }
   ],
   "source": [
    "model = ComplementNB(alpha=2)\n",
    "report, roc_auc = evaluate_model(tfidf_train, train_df['label'], tfidf_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84     12500\n",
      "           1       0.85      0.82      0.83     12500\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "0.9174319872\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(loss='modified_huber', penalty='l1', max_iter=200, eta0=.00001, learning_rate='adaptive')\n",
    "report, roc_auc = evaluate_model(tfidf_train, train_df['label'], tfidf_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_importance</th>\n",
       "      <th>bad_word</th>\n",
       "      <th>good_importance</th>\n",
       "      <th>good_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.813811</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.623438</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.593837</td>\n",
       "      <td>worst</td>\n",
       "      <td>0.401352</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.424598</td>\n",
       "      <td>waste</td>\n",
       "      <td>0.391234</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393516</td>\n",
       "      <td>awful</td>\n",
       "      <td>0.372001</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.335350</td>\n",
       "      <td>terrible</td>\n",
       "      <td>0.320569</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.327765</td>\n",
       "      <td>boring</td>\n",
       "      <td>0.281778</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.317120</td>\n",
       "      <td>plot</td>\n",
       "      <td>0.278429</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.299869</td>\n",
       "      <td>stupid</td>\n",
       "      <td>0.262683</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.298736</td>\n",
       "      <td>worse</td>\n",
       "      <td>0.250405</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.298032</td>\n",
       "      <td>minute</td>\n",
       "      <td>0.249714</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad_importance  bad_word  good_importance    good_word\n",
       "0       -0.813811       bad         0.623438        great\n",
       "1       -0.593837     worst         0.401352         best\n",
       "2       -0.424598     waste         0.391234         love\n",
       "3       -0.393516     awful         0.372001    excellent\n",
       "4       -0.335350  terrible         0.320569    wonderful\n",
       "5       -0.327765    boring         0.281778  performance\n",
       "6       -0.317120      plot         0.278429         life\n",
       "7       -0.299869    stupid         0.262683     favorite\n",
       "8       -0.298736     worse         0.250405      perfect\n",
       "9       -0.298032    minute         0.249714        loved"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances(tfidf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     12500\n",
      "           1       0.88      0.88      0.88     12500\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "0.9510070144\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='newton-cg', penalty='l2', max_iter=100, C=2)\n",
    "report, roc_auc = evaluate_model(tfidf_train, train_df['label'], tfidf_test, test_df['label'], model)\n",
    "print(report)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_importance</th>\n",
       "      <th>bad_word</th>\n",
       "      <th>good_importance</th>\n",
       "      <th>good_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.642100</td>\n",
       "      <td>worst</td>\n",
       "      <td>7.945864</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.018004</td>\n",
       "      <td>waste</td>\n",
       "      <td>7.516254</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.988801</td>\n",
       "      <td>awful</td>\n",
       "      <td>5.993586</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.732067</td>\n",
       "      <td>bad</td>\n",
       "      <td>5.881730</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.583371</td>\n",
       "      <td>boring</td>\n",
       "      <td>5.683254</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.193961</td>\n",
       "      <td>poor</td>\n",
       "      <td>5.547731</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-5.893898</td>\n",
       "      <td>worse</td>\n",
       "      <td>4.906980</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5.851771</td>\n",
       "      <td>poorly</td>\n",
       "      <td>4.634467</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.558549</td>\n",
       "      <td>disappointment</td>\n",
       "      <td>4.560583</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.376655</td>\n",
       "      <td>dull</td>\n",
       "      <td>4.381601</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad_importance        bad_word  good_importance  good_word\n",
       "0      -10.642100           worst         7.945864      great\n",
       "1       -8.018004           waste         7.516254  excellent\n",
       "2       -7.988801           awful         5.993586    perfect\n",
       "3       -7.732067             bad         5.881730       best\n",
       "4       -6.583371          boring         5.683254  wonderful\n",
       "5       -6.193961            poor         5.547731   favorite\n",
       "6       -5.893898           worse         4.906980    amazing\n",
       "7       -5.851771          poorly         4.634467      loved\n",
       "8       -5.558549  disappointment         4.560583      today\n",
       "9       -5.376655            dull         4.381601        fun"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances(tfidf, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF manages to provide better results for Naive Bayes model and Logistic Regression, but gives worse results for SGDClassifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
